{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minhash for recommendations\n",
    "\n",
    "In the [previous notebook](04-minhash.ipynb) we saw how Minhash can be used to approximate the similarity of sets. In this notebook we will see that Minhash can also be used to make recommendations. \n",
    "\n",
    "We illustrate this technique using a data set which contains users' listening history from a music streaming service. If you're interested in how we generated this data, take a look at [this notebook](99a-data-generator.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = 'data/' \n",
    "files = os.listdir(path)\n",
    "files_data = [i for i in files if i.startswith('userdat')][0:1] #listing all files in the directory of the correct form\n",
    "df = pd.DataFrame(columns=['user', 'artist','plays'])\n",
    "for j in files_data:\n",
    "    pseudo_data = pd.read_parquet('data/'+j)\n",
    "    df = pd.concat([df, pseudo_data])\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains three columns and over three million rows. Let's take a closer look at a sample of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(10, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is an integer representing a user id, the second is an integer representing an artist name, and the third column is an integer indicating how many times the user listened to the artist. \n",
    "\n",
    "We take one pass through the data to identify all unique artists all unique users and artists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['artist'] = df['artist'].astype('int')\n",
    "df['user'] = df['user'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = df['artist'].unique()\n",
    "users = df['user'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are \", len(artists), \" artists and \", len(users), \" users in our data.\" , sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We map those user names to unique integers and store those in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dusers = {x+1:y for x,y in enumerate(sorted(set(users)))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load in a dictionary which maps from the artist integers to artist names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open(\"data/dartists.pkl\",\"rb\")\n",
    "dartists = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to convert the integers representing artist names back into artist names, using the dictionary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We group the data set by user. From there we can see which artists a particular user has listened to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def user_data(user, grouped_data, dusers):\n",
    "    return grouped_data.get_group(dusers[user]) \n",
    "\n",
    "def top_k_listens(listening_history, k=10):\n",
    "    top_k = listening_history.sort_values(by=\"plays\", ascending = False)[\"artist\"].head(k).values\n",
    "    return artist_names(top_k)\n",
    "\n",
    "def artist_names(artist_ints, artist_dic = dartists):\n",
    "    return [artist_dic[k] for k in artist_ints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(['user'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a particular user we can have a look at their listening history as well as their most listened to artists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "u100 = user_data(100, grouped_df, dusers)\n",
    "u100_samp = u100.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u100_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_listens(u100, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each user, we want to generate a minhash of their listening history. The minhash class which we used in the previous notebook has been put into its own module for ease. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketching.minhash import LSHMinhash\n",
    "from datasketching.minhash import murmurmaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_minhash_sig(user_dat, rows, bands):\n",
    "    mh = LSHMinhash(rows, bands)\n",
    "    for row in user_dat:\n",
    "        mh.add(row)\n",
    "    return mh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for each user, we want to compose a list of all the artists they listened to. From there we will generate minhashes for each user, then make predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_artists = grouped_df['artist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in df.head(10).iloc[:, :]:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "from datasketching.minhash import LSHMinhash\n",
    "\n",
    "# generate minhashes by processing every row of the data frame\n",
    "\n",
    "minhashes = defaultdict(lambda: LSHMinhash(32, 4))\n",
    "\n",
    "for user, artist in zip(df[\"user\"], df[\"artist\"]):\n",
    "    minhashes[user].add(artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this next cell takes about ten minutes to run with 128 nhash\n",
    "## 80 minutes with 1024 hash functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketching.minhash import generate_minhashes_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# generate minhashes by combining single-artist signatures\n",
    "proto = LSHMinhash(32,4)\n",
    "sigs2 = generate_minhashes_for(grouped_df, \"user\", \"artist\", proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mh_sigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sigs2)\n",
    "sigs2[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minhashes[2].similarity(sigs2[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have minhash signatures for all of the users we can compare them. But this isnt a quick process - suppose we want to find users who are similar to user 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim=[]\n",
    "for mh in range(1, len(mh_sigs)):\n",
    "    sim.append(mh_sigs[dusers[mh]].similarity(mh_sigs[dusers[100]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the users who are most similar to user 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = set(sorted(sim, reverse = True)[1:10])\n",
    "similar_users = ([i for i, e in enumerate(sim) if e in similar])\n",
    "for j in similar_users:\n",
    "    print(dusers[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the most similar users. Let's go ahead and look at the top artists listened to by all these users. \n",
    "\n",
    "Going to look at the unique artists listened to by each of these, remove uniques listened to by user 2, and then return the most listened across the other users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the ?top 10 artists most listened to by these users that our user didnt listen to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unheard = []\n",
    "for u in similar_users:\n",
    "    u_dat = user_data(u, grouped_df, dusers)\n",
    "    unheard = unheard + list(top_k_listens(u_dat, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unheard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's just a quick example of how we can use minhash to identify songs we should recommend to a particular user. This method works fine on a small number of users, but falls into dificulty when the number of users grows, and the number of users for which we want to make recommendations for grows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locality-Sensitive Minhash\n",
    "\n",
    "One big disadvantage of using Minhash signatures to identify similar users is the number of pairwise comparisons which must be made to determine similarity. \n",
    "\n",
    "Locality-sensitive Minhash is a technique we can use to identify candidate pairs of similar users for a much smaller computational cost. The method works by hashing subsets minhash signatures. If 2 users have identical signatures in ANY of the subsets these users are considered a candidate pair. And from there you can go and compute their approximate Jaccard index, or similarity, using the full minhash signatures, to determine just how similar they are, and decide if you want to make recommendations. \n",
    "\n",
    "The way in locality sensitive minhash works is by splitting the minhash signatures into bands. The bands are then hashed to buckets. \n",
    "\n",
    "if, in any band, two users map to the same bucket, they would be considered a candidate pair. At that point you’d go back and look at their minhash signatures, and compare those to determine how similar the users are. \n",
    "\n",
    "\n",
    "And thus we only have to compute the similarity of the minhash signatures for a subset of the whole population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketching.minhash import LSHMinhash\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsmh(mh_sig, bands):\n",
    "    ### assumes that the lenth of the mhsig is divisible by bands. \n",
    "    ### make more robust\n",
    "    rows = int(len(mh_sig.buckets)/bands)\n",
    "    return [mh_sig.hashes[0]([b for b in band]) for band in mh_sig.buckets.copy().reshape((rows, bands))]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "bands = [defaultdict(lambda: list()) for i in range(16)]\n",
    "\n",
    "for ind, mh_sg in enumerate(mh_sigs):\n",
    "    for idx, key in enumerate(lsmh(mh_sg, bands=16)):\n",
    "        bands[idx][key % (1 << 14)].append(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've made a dictionary of values for each band, where the keys correspond to buckets, and the values are indexes of minhash signature which mapped to that bucket. \n",
    "\n",
    "If two minhash signatures hash to the same key in ANY band we consider them to be 'candidate pairs'. \n",
    "\n",
    "This means that the corresponding users _may_ be similar. We can check if they are similar by comparing the set of artists they have each listend to. From there we can use this information to make recomendations, or move on to consider other candidate pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
